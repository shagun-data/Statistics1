{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is statistics, and why is it important?\n",
        "- Definition: Statistics is the study of collecting, organizing, analyzing, interpreting, and presenting data. It helps in making informed decisions based on data patterns.\n",
        "\n",
        "- Analogy: Imagine you are the coach of a football team. You track players' performance (goals scored, speed, etc.) to make strategic decisions. Statistics helps us analyze and use data effectively to improve outcomes.\n",
        "\n",
        "2. What are the two main types of statistics?\n",
        "- Definition:\n",
        "Descriptive statistics summarize and present data (e.g., averages, percentages).\n",
        "Inferential statistics make predictions based on a sample of data.\n",
        "Analogy: Think of statistics as a detective's work:\n",
        "\n",
        "- Descriptive: Looking at evidence (fingerprints, shoe prints) to describe what happened.\n",
        "Inferential: Using that evidence to predict who committed the crime.\n",
        "\n",
        "3. What are descriptive statistics?\n",
        "- Definition: Descriptive statistics summarize and organize data using measures like mean, median, mode, and standard deviation.\n",
        "\n",
        "- Analogy: Running a bakery and keeping track of daily sales—recording how many cookies are sold, the most popular flavor, and the total revenue. This helps in understanding business trends.\n",
        "\n",
        "4. What is inferential statistics?\n",
        "- Definition: Inferential statistics use sample data to make conclusions or predictions about a larger population.\n",
        "\n",
        "- Analogy: Tasting a spoonful of soup to decide if the whole pot needs more salt. You're using a small portion to infer something about the entire batch.\n",
        "\n",
        "5. What is sampling in statistics?\n",
        "- Definition: Sampling is the process of selecting a small group from a larger population to analyze and make conclusions.\n",
        "\n",
        "- Analogy: Checking a handful of rice from a large bag to determine its quality instead of inspecting every grain.\n",
        "\n",
        "6. What are the different types of sampling methods?\n",
        "- Definition:\n",
        "Random Sampling: Every individual has an equal chance of selection.\n",
        "Stratified Sampling: Population divided into groups, and samples taken from each.\n",
        "- Systematic Sampling: Selecting every nth individual.\n",
        "Cluster Sampling: Selecting whole groups instead of individuals.\n",
        "Convenience Sampling: Selecting the easiest-to-reach individuals.\n",
        "Analogy: Picking apples from a tree:\n",
        "\n",
        "- Random: Picking apples with eyes closed.\n",
        "- Stratified: Taking some apples from each branch.\n",
        "- Systematic: Picking every 10th apple.\n",
        "- Cluster: Picking all apples from one branch.\n",
        "- Convenience: Picking the closest apples.\n",
        "7. What is the difference between random and non-random sampling?\n",
        "- Definition:\n",
        "Random sampling is unbiased; every individual has an equal chance of selection.\n",
        "Non-random sampling is biased and based on convenience or judgment.\n",
        "- Analogy: Selecting players for a football team:\n",
        "\n",
        "- Random: Writing names on paper, shuffling, and picking.\n",
        "- Non-random: Choosing players who \"look\" strong.\n",
        "8. Define and give examples of qualitative and quantitative data.\n",
        "- Definition:\n",
        "Qualitative data is descriptive (e.g., colors, names, opinions).\n",
        "Quantitative data is numerical (e.g., height, temperature).\n",
        "- Analogy: A restaurant review:\n",
        "Qualitative: \"The food was delicious.\"\n",
        "Quantitative: \"The food was rated 4.5/5.\"\n",
        "9. What are the different types of data in statistics?\n",
        "- Definition:\n",
        "Nominal: Categories without order (e.g., colors, brands).\n",
        "Ordinal: Categories with order (e.g., movie rankings).\n",
        "Interval: Numeric values without a true zero (e.g., temperature).\n",
        "Ratio: Numeric values with a true zero (e.g., height, weight).\n",
        "- Analogy: A music app:\n",
        "Nominal: Genre (Rock, Pop).\n",
        "Ordinal: Top 10 songs.\n",
        "Interval: Year of release.\n",
        "Ratio: Number of times a song is played.\n",
        "10. Explain nominal, ordinal, interval, and ratio levels of measurement.\n",
        "- Analogy: A marathon:\n",
        "Nominal: Runner's nationality (Indian, American).\n",
        "Ordinal: Rank in the race (1st, 2nd, 3rd).\n",
        "Interval: Temperature on race day.\n",
        "Ratio: Time taken to finish the race.\n",
        "11. What is the measure of central tendency?\n",
        "- Definition: It identifies the center of a dataset using mean, median, or mode.\n",
        "\n",
        "- Analogy: Finding the \"typical\" height of students in a class.\n",
        "\n",
        "12. Define mean, median, and mode.\n",
        "- Analogy: A bakery:\n",
        "Mean: Average price of cakes.\n",
        "Median: Middle-priced cake when sorted.\n",
        "Mode: Most popular flavor.\n",
        "13. What is the significance of the measure of central tendency?\n",
        "- Analogy: Choosing a city to live in based on average rent, middle-range prices, or most common house cost.\n",
        "\n",
        "14. What is variance, and how is it calculated?\n",
        "- Definition: Variance measures how much data points differ from the mean.\n",
        "\n",
        "- Analogy: Comparing student grades to see if scores are similar or widely spread.\n",
        "\n",
        "15. What is standard deviation, and why is it important?\n",
        "- Analogy: A race:\n",
        "Low standard deviation: All runners finish close together.\n",
        "High standard deviation: Some runners finish much earlier or later.\n",
        "16. Define and explain the term range in statistics.\n",
        "- Analogy: The age gap in a family (oldest age - youngest age).\n",
        "\n",
        "17. What is the difference between variance and standard deviation?\n",
        "- Analogy: Variance is like squaring differences, while standard deviation is like taking the square root for easier interpretation.\n",
        "\n",
        "18. What is skewness in a dataset?\n",
        "- Analogy: A seesaw:\n",
        "If most kids sit on one side, it leans (skewed).\n",
        "If kids sit evenly, it’s balanced.\n",
        "19. What does it mean if a dataset is positively or negatively skewed?\n",
        "- Analogy:\n",
        "- Positive Skew: A salary dataset where most people earn low, but a few earn extremely high.\n",
        "- Negative Skew: Exam scores where most students score high, but a few score low.\n",
        "20. Define and explain kurtosis.\n",
        "- Analogy: A mountain shape:\n",
        "A sharp peak = high kurtosis (data tightly packed).\n",
        "A flat peak = low kurtosis (data spread out).\n",
        "21. What is the purpose of covariance?\n",
        "- Analogy: Ice cream sales increase when temperatures rise—covariance shows they are related but doesn’t measure strength.\n",
        "\n",
        "22. What does correlation measure in statistics?\n",
        "- Analogy: A dance:\n",
        "If two dancers move in sync, strong correlation.\n",
        "If they move randomly, weak correlation.\n",
        "23. What is the difference between covariance and correlation?\n",
        "- Analogy:\n",
        "Covariance: Two friends go to the gym together but the bond strength is unknown.\n",
        "Correlation: The bond strength is measured from -1 to 1.\n",
        "24. What are some real-world applications of statistics?\n",
        "- Healthcare: Predicting disease outbreaks.\n",
        " Finance: Stock market analysis.\n",
        "- Sports: Player performance.\n",
        " Marketing: Customer preferences.\n"
      ],
      "metadata": {
        "id": "e7oRxvSFS30P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. How do you calculate the mean, median, and mode of a dataset\n",
        "# Mean\n",
        "def calculate_mean(data):\n",
        "    return sum(data) / len(data)\n",
        "\n",
        "# Median\n",
        "def calculate_median(data):\n",
        "    sorted_data = sorted(data)\n",
        "    n = len(sorted_data)\n",
        "    mid = n // 2\n",
        "    if n % 2 == 0:\n",
        "        return (sorted_data[mid - 1] + sorted_data[mid]) / 2\n",
        "    else:\n",
        "        return sorted_data[mid]\n",
        "\n",
        "# Mode\n",
        "from collections import Counter\n",
        "\n",
        "def calculate_mode(data):\n",
        "    freq = Counter(data)\n",
        "    max_freq = max(freq.values())\n",
        "    modes = [key for key, val in freq.items() if val == max_freq]\n",
        "    return modes if len(modes) > 1 else modes[0]\n",
        "\n",
        "# Example usage\n",
        "data = [1, 2, 2, 3, 4, 5, 5, 5]\n",
        "print(\"Mean:\", calculate_mean(data))\n",
        "print(\"Median:\", calculate_median(data))\n",
        "print(\"Mode:\", calculate_mode(data))\n",
        "\n"
      ],
      "metadata": {
        "id": "6P8DM2SWUSXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 Write a Python program to compute the variance and standard deviation of a dataset\n",
        "import statistics\n",
        "\n",
        "# Function to compute variance and standard deviation\n",
        "def compute_variance_std(data):\n",
        "    variance = statistics.variance(data)  # Sample variance\n",
        "    std_dev = statistics.stdev(data)  # Sample standard deviation\n",
        "    return variance, std_dev\n",
        "\n",
        "# Example usage\n",
        "data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "variance, std_dev = compute_variance_std(data)\n",
        "\n",
        "print(\"Variance:\", variance)\n",
        "print(\"Standard Deviation:\", std_dev)\n",
        "\n"
      ],
      "metadata": {
        "id": "9ciOAFk4U6Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 Create a dataset and classify it into nominal, ordinal, interval, and ratio types\n",
        "# Creating a dataset with different types of data\n",
        "\n",
        "dataset = {\n",
        "    \"Nominal\": [\"Red\", \"Blue\", \"Green\", \"Yellow\"],  # Categories with no order\n",
        "    \"Ordinal\": [\"Poor\", \"Average\", \"Good\", \"Excellent\"],  # Ordered categories but no fixed differences\n",
        "    \"Interval\": [-10, 0, 10, 20, 30],  # Numerical, ordered, with equal intervals, but no true zero\n",
        "    \"Ratio\": [5, 10, 15, 20, 25]  # Numerical, ordered, equal intervals, and has a true zero\n",
        "}\n",
        "\n",
        "# Displaying the dataset\n",
        "for data_type, values in dataset.items():\n",
        "    print(f\"{data_type} Data: {values}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "C6FW3VWoVGhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 Implement sampling techniques like random sampling and stratified sampling\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Creating a sample dataset\n",
        "data = {'ID': list(range(1, 21)), 'Category': ['A']*10 + ['B']*10}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Random Sampling (Simple Random Sampling)\n",
        "random_sample = df.sample(n=5, random_state=42)\n",
        "\n",
        "# Stratified Sampling (Ensuring equal representation from each category)\n",
        "stratified_sample, _ = train_test_split(df, test_size=0.75, stratify=df['Category'], random_state=42)\n",
        "\n",
        "# Display results\n",
        "print(\"Random Sample:\\n\", random_sample)\n",
        "print(\"\\nStratified Sample:\\n\", stratified_sample)\n"
      ],
      "metadata": {
        "id": "lQYxEBSnVO25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 Write a Python function to calculate the range of a dataset\n",
        "# Function to calculate the range of a dataset\n",
        "def calculate_range(data):\n",
        "    return max(data) - min(data)\n",
        "\n",
        "# Example usage\n",
        "data = [4, 8, 15, 16, 23, 42]\n",
        "print(\"Range:\", calculate_range(data))\n"
      ],
      "metadata": {
        "id": "deQhsfspVXYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 Create a dataset and plot its histogram to visualize skewness\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creating a right-skewed dataset\n",
        "data = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Plotting the histogram\n",
        "plt.hist(data, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "plt.title(\"Histogram to Visualize Skewness\")\n",
        "plt.xlabel(\"Values\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Sa24iaCQVef8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  7 Calculate skewness and kurtosis of a dataset using Python libraries\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Creating a dataset\n",
        "data = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Calculating skewness and kurtosis\n",
        "skewness = stats.skew(data)\n",
        "kurtosis = stats.kurtosis(data)  # Fisher’s definition (default, subtracts 3 for normal distribution)\n",
        "\n",
        "# Display results\n",
        "print(\"Skewness:\", skewness)\n",
        "print(\"Kurtosis:\", kurtosis)\n"
      ],
      "metadata": {
        "id": "qDm5AHhLVnIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 Generate a dataset and demonstrate positive and negative skewness\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generating a positively skewed dataset (Right-skewed)\n",
        "positive_skew = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Generating a negatively skewed dataset (Left-skewed)\n",
        "negative_skew = np.random.beta(a=5, b=2, size=1000) * 10\n",
        "\n",
        "# Plotting histograms\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "axes[0].hist(positive_skew, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "axes[0].set_title(\"Positively Skewed Distribution\")\n",
        "axes[0].set_xlabel(\"Values\")\n",
        "axes[0].set_ylabel(\"Frequency\")\n",
        "\n",
        "axes[1].hist(negative_skew, bins=30, color='lightcoral', edgecolor='black', alpha=0.7)\n",
        "axes[1].set_title(\"Negatively Skewed Distribution\")\n",
        "axes[1].set_xlabel(\"Values\")\n",
        "axes[1].set_ylabel(\"Frequency\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qhCskkKyVv9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9 Write a Python script to calculate covariance between two datasets\n",
        "import numpy as np\n",
        "\n",
        "# Creating two datasets\n",
        "x = [10, 20, 30, 40, 50]\n",
        "y = [5, 15, 25, 35, 45]\n",
        "\n",
        "# Calculating covariance\n",
        "cov_matrix = np.cov(x, y, bias=False)  # Unbiased estimate (default)\n",
        "covariance = cov_matrix[0, 1]\n",
        "\n",
        "# Display result\n",
        "print(\"Covariance:\", covariance)\n"
      ],
      "metadata": {
        "id": "RAnGInxHV2pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 Write a Python script to calculate the correlation coefficient between two datasets\n",
        "import numpy as np\n",
        "\n",
        "# Creating two datasets\n",
        "x = [10, 20, 30, 40, 50]\n",
        "y = [5, 15, 25, 35, 45]\n",
        "\n",
        "# Calculating correlation coefficient\n",
        "correlation_matrix = np.corrcoef(x, y)\n",
        "correlation_coefficient = correlation_matrix[0, 1]\n",
        "\n",
        "# Display result\n",
        "print(\"Correlation Coefficient:\", correlation_coefficient)\n"
      ],
      "metadata": {
        "id": "RnzvzqPjV-tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11 Create a scatter plot to visualize the relationship between two variables\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generating sample data\n",
        "x = np.random.rand(50) * 10  # Random values between 0 and 10\n",
        "y = 2 * x + np.random.randn(50) * 2  # Linear relationship with noise\n",
        "\n",
        "# Creating scatter plot\n",
        "plt.scatter(x, y, color='blue', alpha=0.7, edgecolors='black')\n",
        "plt.title(\"Scatter Plot of Two Variables\")\n",
        "plt.xlabel(\"X values\")\n",
        "plt.ylabel(\"Y values\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "khupiCpBWHg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12 Implement and compare simple random sampling and systematic sampling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a sample dataset\n",
        "data = pd.DataFrame({'ID': np.arange(1, 21), 'Value': np.random.randint(1, 100, 20)})\n",
        "\n",
        "# Simple Random Sampling\n",
        "random_sample = data.sample(n=5, random_state=42)\n",
        "\n",
        "# Systematic Sampling (Select every k-th element)\n",
        "k = len(data) // 5  # Sample size = 5\n",
        "systematic_sample = data.iloc[::k]\n",
        "\n",
        "# Display results\n",
        "print(\"Simple Random Sampling:\\n\", random_sample)\n",
        "print(\"\\nSystematic Sampling:\\n\", systematic_sample)\n"
      ],
      "metadata": {
        "id": "WegDRGNmWVRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13 Calculate the mean, median, and mode of grouped data\n",
        "import pandas as pd\n",
        "import statistics as stats\n",
        "\n",
        "# Creating grouped data (class intervals and frequencies)\n",
        "data = {\n",
        "    \"Class Interval\": [\"0-10\", \"10-20\", \"20-30\", \"30-40\", \"40-50\"],\n",
        "    \"Frequency\": [5, 8, 15, 10, 7]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculating midpoints\n",
        "df[\"Midpoint\"] = df[\"Class Interval\"].apply(lambda x: (int(x.split('-')[0]) + int(x.split('-')[1])) / 2)\n",
        "\n",
        "# Calculating Mean\n",
        "mean = sum(df[\"Midpoint\"] * df[\"Frequency\"]) / sum(df[\"Frequency\"])\n",
        "\n",
        "# Calculating Median\n",
        "cumulative_freq = df[\"Frequency\"].cumsum()\n",
        "n = sum(df[\"Frequency\"]) / 2\n",
        "median_class = df[cumulative_freq >= n].iloc[0]\n",
        "L = int(median_class[\"Class Interval\"].split('-')[0])  # Lower boundary\n",
        "F = cumulative_freq[df[\"Class Interval\"] == median_class[\"Class Interval\"]].iloc[0] - median_class[\"Frequency\"]\n",
        "f = median_class[\"Frequency\"]\n",
        "h = int(median_class[\"Class Interval\"].split('-')[1]) - L\n",
        "\n",
        "median = L + ((n - F) / f) * h\n",
        "\n",
        "# Calculating Mode\n",
        "mode_class = df.iloc[df[\"Frequency\"].idxmax()]\n",
        "L_mode = int(mode_class[\"Class Interval\"].split('-')[0])\n",
        "f1 = mode_class[\"Frequency\"]\n",
        "f0 = df.iloc[df[\"Frequency\"].idxmax() - 1][\"Frequency\"] if df[\"Frequency\"].idxmax() > 0 else 0\n",
        "f2 = df.iloc[df[\"Frequency\"].idxmax() + 1][\"Frequency\"] if df[\"Frequency\"].idxmax() < len(df) - 1 else 0\n",
        "h_mode = int(mode_class[\"Class Interval\"].split('-')[1]) - L_mode\n",
        "\n",
        "mode = L_mode + ((f1 - f0) / ((f1 - f0) + (f1 - f2))) * h_mode if (f1 - f0) + (f1 - f2) != 0 else L_mode\n",
        "\n",
        "# Display results\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Median:\", median)\n",
        "print(\"Mode:\", mode)\n"
      ],
      "metadata": {
        "id": "-SE6CzKEWeB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14 Simulate data using Python and calculate its central tendency and dispersion.\n",
        "import numpy as np\n",
        "import statistics as stats\n",
        "\n",
        "# Simulating data (random normal distribution)\n",
        "data = np.random.normal(loc=50, scale=15, size=1000)  # Mean=50, Std Dev=15, 1000 samples\n",
        "\n",
        "# Calculating central tendency\n",
        "mean = np.mean(data)\n",
        "median = np.median(data)\n",
        "mode = stats.mode(data)\n",
        "\n",
        "# Calculating dispersion\n",
        "variance = np.var(data, ddof=1)  # Sample variance\n",
        "std_dev = np.std(data, ddof=1)  # Sample standard deviation\n",
        "range_value = np.ptp(data)  # Range\n",
        "\n",
        "# Display results\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Median:\", median)\n",
        "print(\"Mode:\", mode)\n",
        "print(\"Variance:\", variance)\n",
        "print(\"Standard Deviation:\", std_dev)\n",
        "print(\"Range:\", range_value)\n"
      ],
      "metadata": {
        "id": "Dxnn8MmtWpak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15 Use NumPy or pandas to summarize a dataset’s descriptive statistics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a sample dataset\n",
        "data = {\n",
        "    \"Age\": np.random.randint(18, 60, 100),\n",
        "    \"Salary\": np.random.randint(30000, 120000, 100),\n",
        "    \"Experience\": np.random.randint(1, 40, 100)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Summary statistics using pandas\n",
        "summary = df.describe()\n",
        "\n",
        "# Display results\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "J6hYr9huW0hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16 Plot a boxplot to understand the spread and identify outliers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creating a sample dataset\n",
        "np.random.seed(42)\n",
        "data = np.random.randint(10, 100, 50)\n",
        "\n",
        "# Plotting the boxplot\n",
        "plt.boxplot(data, vert=False, patch_artist=True, boxprops=dict(facecolor='lightblue'))\n",
        "plt.title(\"Boxplot to Identify Outliers\")\n",
        "plt.xlabel(\"Values\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Qoaxk64xW-Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17 Calculate the interquartile range (IQR) of a dataset\n",
        "import numpy as np\n",
        "\n",
        "# Creating a sample dataset\n",
        "data = np.array([10, 15, 20, 25, 30, 35, 40, 50, 60, 100])\n",
        "\n",
        "# Calculating Q1 (25th percentile) and Q3 (75th percentile)\n",
        "Q1 = np.percentile(data, 25)\n",
        "Q3 = np.percentile(data, 75)\n",
        "\n",
        "# Calculating IQR\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Display result\n",
        "print(\"Interquartile Range (IQR):\", IQR)\n"
      ],
      "metadata": {
        "id": "5wdJ7HjUXGUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 18 Implement Z-score normalization and explain its significance\n",
        "import numpy as np\n",
        "\n",
        "# Creating a sample dataset\n",
        "data = np.array([10, 15, 20, 25, 30, 35, 40, 50, 60, 100])\n",
        "\n",
        "# Calculating Q1 (25th percentile) and Q3 (75th percentile)\n",
        "Q1 = np.percentile(data, 25)\n",
        "Q3 = np.percentile(data, 75)\n",
        "\n",
        "# Calculating IQR\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Display result\n",
        "print(\"Interquartile Range (IQR):\", IQR)\n"
      ],
      "metadata": {
        "id": "5ayrdoPjXNV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 19 Compare two datasets using their standard deviations\n",
        "import numpy as np\n",
        "\n",
        "# Creating two sample datasets\n",
        "data1 = np.random.normal(loc=50, scale=10, size=1000)  # Mean=50, Std Dev=10\n",
        "data2 = np.random.normal(loc=50, scale=20, size=1000)  # Mean=50, Std Dev=20\n",
        "\n",
        "# Calculating standard deviations\n",
        "std_dev1 = np.std(data1, ddof=1)\n",
        "std_dev2 = np.std(data2, ddof=1)\n",
        "\n",
        "# Display results\n",
        "print(\"Standard Deviation of Dataset 1:\", std_dev1)\n",
        "print(\"Standard Deviation of Dataset 2:\", std_dev2)\n",
        "\n",
        "# Interpretation\n",
        "if std_dev1 > std_dev2:\n",
        "    print(\"Dataset 1 has more variability.\")\n",
        "elif std_dev1 < std_dev2:\n",
        "    print(\"Dataset 2 has more variability.\")\n",
        "else:\n",
        "    print(\"Both datasets have equal variability.\")\n"
      ],
      "metadata": {
        "id": "hfVc8ZI5XXmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20 Write a Python program to visualize covariance using a heatmap\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creating a sample dataset\n",
        "np.random.seed(42)\n",
        "data = {\n",
        "    \"X\": np.random.randint(10, 100, 50),\n",
        "    \"Y\": np.random.randint(10, 100, 50),\n",
        "    \"Z\": np.random.randint(10, 100, 50)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculating covariance matrix\n",
        "cov_matrix = df.cov()\n",
        "\n",
        "# Plotting heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cov_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Covariance Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3P5F6GL6XcEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 21 Use seaborn to create a correlation matrix for a dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creating a sample dataset\n",
        "np.random.seed(42)\n",
        "data = {\n",
        "    \"Age\": np.random.randint(18, 60, 50),\n",
        "    \"Salary\": np.random.randint(30000, 120000, 50),\n",
        "    \"Experience\": np.random.randint(1, 40, 50),\n",
        "    \"Score\": np.random.randint(50, 100, 50)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculating correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Plotting heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Matrix Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "grLWTeXhXk7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 22 Generate a dataset and implement both variance and standard deviation computations\n",
        "import numpy as np\n",
        "\n",
        "# Generating a random dataset\n",
        "data = np.random.randint(10, 100, 50)  # 50 random values between 10 and 100\n",
        "\n",
        "# Computing variance and standard deviation\n",
        "variance = np.var(data, ddof=1)  # Sample variance\n",
        "std_dev = np.std(data, ddof=1)  # Sample standard deviation\n",
        "\n",
        "# Display results\n",
        "print(\"Dataset:\", data)\n",
        "print(\"Variance:\", variance)\n",
        "print(\"Standard Deviation:\", std_dev)\n"
      ],
      "metadata": {
        "id": "m91018pvXwZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 23 Visualize skewness and kurtosis using Python libraries like matplotlib or seaborn\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Generating a skewed dataset\n",
        "data = np.random.exponential(scale=2, size=1000)\n",
        "\n",
        "# Calculating skewness and kurtosis\n",
        "skewness = skew(data)\n",
        "kurt = kurtosis(data)\n",
        "\n",
        "# Plotting histogram with density curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(data, kde=True, color=\"skyblue\", bins=30)\n",
        "plt.title(f\"Skewness: {skewness:.2f}, Kurtosis: {kurt:.2f}\")\n",
        "plt.xlabel(\"Values\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mgHsuCS4X1oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 24 Implement the Pearson and Spearman correlation coefficients for a dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# Generating a sample dataset\n",
        "np.random.seed(42)\n",
        "data = {\n",
        "    \"X\": np.random.randint(10, 100, 50),\n",
        "    \"Y\": np.random.randint(10, 100, 50)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculating Pearson and Spearman correlation coefficients\n",
        "pearson_corr, _ = pearsonr(df[\"X\"], df[\"Y\"])\n",
        "spearman_corr, _ = spearmanr(df[\"X\"], df[\"Y\"])\n",
        "\n",
        "# Display results\n",
        "print(\"Pearson Correlation Coefficient:\", pearson_corr)\n",
        "print(\"Spearman Correlation Coefficient:\", spearman_corr)\n"
      ],
      "metadata": {
        "id": "f-dlOV71YBe9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}